debug_mode: false
device: GPU
runtime:
  all_reduce_alg: null
  batchnorm_spatial_persistent: false
  dataset_num_private_threads: null
  default_shard_dim: -1
  distribution_strategy: mirrored
  enable_xla: false
  gpu_thread_mode: null
  loss_scale: null
  mixed_precision_dtype: float16
  num_cores_per_replica: 1
  num_gpus: 0
  num_packs: 1
  per_gpu_thread_count: 0
  run_eagerly: false
  task_index: -1
  tpu: null
  tpu_enable_xla_dynamic_padder: null
  use_tpu_mp_strategy: false
  worker_hosts: null
task:
  allow_image_summary: false
  differential_privacy_config: null
  eval_input_partition_dims: []
  evaluation:
    precision_and_recall_thresholds: null
    report_per_class_precision_and_recall: false
    top_k: 5
  freeze_backbone: false
  init_checkpoint: /home/shashank/cv/vit_resnet_finetuning/checkpoints/vit-deit-imagenet-b16/
  init_checkpoint_modules: backbone
  losses:
    alpha: 0.25
    gamma: 2
    l2_weight_decay: 0.0
    label_smoothing: 0.0
    loss_weight: 1.0
    one_hot: true
    soft_labels: false
    use_binary_cross_entropy: false
    use_categorical_focal_loss: true
    use_focal_loss: false
  model:
    add_head_batch_norm: false
    backbone:
      type: vit
      vit:
        hidden_size: 1
        init_stochastic_depth_rate: 0.1
        layer_scale_init_value: 0.0
        model_name: vit-b16
        original_init: false
        output_2d_feature_maps: false
        output_attention_scores: false
        output_encoded_tokens: true
        patch_size: 16
        pooler: token
        pos_embed_shape: null
        representation_size: 0
        transformer:
          attention_dropout_rate: 0.0
          dropout_rate: 0.0
          mlp_dim: 1
          num_heads: 1
          num_layers: 1
        transformer_partition_dims: null
    dropout_rate: 0.0
    input_size: [224, 224, 3]
    kernel_initializer: zeros
    norm_activation:
      activation: relu
      norm_epsilon: 0.001
      norm_momentum: 0.99
      use_sync_bn: false
    num_classes: 10
    output_softmax: false
  model_output_keys: []
  name: null
  train_data:
    apply_tf_data_service_before_batching: false
    aug_crop: true
    aug_policy: null
    aug_rand_hflip: true
    aug_type:
      randaug:
        cutout_const: 40
        exclude_ops:
        - Cutout
        magnitude: 9
        magnitude_std: 0.0
        num_layers: 2
        prob_to_apply: null
        translate_const: 10
      type: randaug
    autotune_algorithm: null
    block_length: 1
    cache: false
    center_crop_fraction: 0.875
    color_jitter: 0.0
    crop_area_range: !!python/tuple
    - 0.08
    - 1.0
    cycle_length: 10
    decode_jpeg_only: false
    decoder:
      simple_decoder:
        attribute_names: []
        mask_binarize_threshold: null
        regenerate_source_id: false
      type: simple_decoder
    deterministic: null
    drop_remainder: true
    dtype: float16
    enable_shared_tf_data_service_between_parallel_trainers: false
    enable_tf_data_service: false
    file_type: tfrecord
    global_batch_size: 16
    image_field_key: image/encoded
    input_path: /home/shashank/tensorflow_datasets/tfrecords/ArtDL/train-00000-of-00001.tfrecord
    is_multilabel: false
    is_training: true
    label_field_key: image/label
    mixup_and_cutmix: null
    prefetch_buffer_size: null
    ram_budget: null
    randaug_magnitude: 10
    random_erasing: null
    repeated_augment: null
    seed: null
    sharding: true
    shuffle_buffer_size: 10000
    tf_data_service_address: null
    tf_data_service_job_name: null
    tf_resize_method: bilinear
    tfds_as_supervised: false
    tfds_data_dir: ''
    tfds_name: ''
    tfds_skip_decoding_feature: ''
    tfds_split: ''
    three_augment: false
    trainer_id: null
    weights: null
  train_input_partition_dims: []
  validation_data:
    apply_tf_data_service_before_batching: false
    aug_crop: true
    aug_policy: null
    aug_rand_hflip: true
    aug_type: null
    autotune_algorithm: null
    block_length: 1
    cache: false
    center_crop_fraction: 0.875
    color_jitter: 0.0
    crop_area_range: !!python/tuple
    - 0.08
    - 1.0
    cycle_length: 10
    decode_jpeg_only: false
    decoder:
      simple_decoder:
        attribute_names: []
        mask_binarize_threshold: null
        regenerate_source_id: false
      type: simple_decoder
    deterministic: null
    drop_remainder: false
    dtype: float16
    enable_shared_tf_data_service_between_parallel_trainers: false
    enable_tf_data_service: false
    file_type: tfrecord
    global_batch_size: 16
    image_field_key: image/encoded
    input_path: /home/shashank/tensorflow_datasets/tfrecords/ArtDL/val-00000-of-00001.tfrecord
    is_multilabel: false
    is_training: false
    label_field_key: image/label
    mixup_and_cutmix: null
    prefetch_buffer_size: null
    ram_budget: null
    randaug_magnitude: 10
    random_erasing: null
    repeated_augment: null
    seed: null
    sharding: true
    shuffle_buffer_size: 10000
    tf_data_service_address: null
    tf_data_service_job_name: null
    tf_resize_method: bilinear
    tfds_as_supervised: false
    tfds_data_dir: ''
    tfds_name: ''
    tfds_skip_decoding_feature: ''
    tfds_split: ''
    three_augment: false
    trainer_id: null
    weights: null
trainer:
  allow_tpu_summary: false
  best_checkpoint_eval_metric: ''
  best_checkpoint_export_subdir: ''
  best_checkpoint_metric_comp: higher
  checkpoint_interval: 6
  continuous_eval_timeout: 3600
  eval_tf_function: true
  eval_tf_while_loop: false
  loss_upper_bound: 1000000.0
  max_to_keep: 5
  optimizer_config:
    ema: null
    learning_rate:
      cosine:
        alpha: 0.0
        decay_steps: 90000
        initial_learning_rate: 0.0001
        name: CosineDecay
        offset: 0
      type: cosine
    optimizer:
      adamw:
        amsgrad: false
        beta_1: 0.9
        beta_2: 0.999
        clipnorm: null
        clipvalue: null
        epsilon: 1.0e-07
        exclude_from_weight_decay: null
        global_clipnorm: null
        gradient_clip_norm: 0.0
        include_in_weight_decay: .*(kernel|weight):0$
        name: AdamWeightDecay
        weight_decay_rate: 0.05
      type: adamw
    warmup:
      linear:
        name: linear
        warmup_learning_rate: 0
        warmup_steps: 100
      type: linear
  preemption_on_demand_checkpoint: true
  recovery_begin_steps: 0
  recovery_max_trials: 0
  steps_per_loop: 1000
  summary_interval: 1000
  train_steps: 90000
  train_tf_function: true
  train_tf_while_loop: true
  validation_interval: 9000
  validation_steps: -1
  validation_summary_subdir: validation
